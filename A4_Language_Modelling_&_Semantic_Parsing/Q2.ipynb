{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import nltk\n",
    "from nltk.data import find\n",
    "import gensim\n",
    "import sklearn\n",
    "from sympy.parsing.sympy_parser import parse_expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package word2vec_sample to\n",
      "[nltk_data]     C:\\Users\\chatu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package word2vec_sample is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "nltk.download('word2vec_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text2SQLParser:\n",
    "\tdef __init__(self):\n",
    "\t\t\"\"\"\n",
    "\t\tBasic Text2SQL Parser. This module just attempts to classify the user queries into different \"categories\" of SQL queries.\n",
    "\t\t\"\"\"\n",
    "\t\tself.parser_files = \"data/semantic-parser\"\n",
    "\t\tself.word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
    "\t\tself.word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(self.word2vec_sample, binary=False)\n",
    "\n",
    "\t\tself.train_file = \"sql_train.tsv\"\n",
    "\t\tself.test_file = \"sql_val.tsv\"\n",
    "\n",
    "\tdef load_data(self):\n",
    "\t\t\"\"\"\n",
    "\t\tLoad the data from file.\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\t\t\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\t\"\"\"\n",
    "\t\tself.train_df = pd.read_csv(self.parser_files + \"/\" + self.train_file, sep=\"\\t\")\n",
    "\t\tself.test_df = pd.read_csv(self.parser_files + \"/\" + self.test_file, sep=\"\\t\")\n",
    "\n",
    "\t\tself.ls_labels = list(self.train_df[\"Label\"].unique())\n",
    "\n",
    "\tdef predict_label_using_keywords(self, question):\n",
    "\t\t\"\"\"\n",
    "\t\tPredicts the label for the question using custom-defined keywords.\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tquestion: str\n",
    "\t\t\tThe question whose label is to be predicted.\n",
    "\t\t\t\t\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tlabel: str\n",
    "\t\t\tThe predicted label.\n",
    "\t\t\"\"\"\n",
    "\t\t# Convert to lowercase for case-insensitive matching\n",
    "\t\tquestion_lower = question.lower()\n",
    "\t\t\n",
    "\t\t# Define keyword dictionaries with weights for each category\n",
    "\t\t# Higher weights for more specific/strong indicators\n",
    "\t\tkeywords = {\n",
    "\t\t\t\"comparison\": {\n",
    "\t\t\t\t\"greater than\": 2, \"less than\": 2, \"equal to\": 2, \"more than\": 2, \"fewer than\": 2, \n",
    "\t\t\t\t\"between\": 1.5, \"compare\": 1, \"highest\": 1.5, \"lowest\": 1.5, \"maximum\": 2, \n",
    "\t\t\t\t\"minimum\": 2, \"largest\": 1.5, \"smallest\": 1.5, \"where\": 1.5, \"exceed\": 1,\n",
    "\t\t\t\t\"condition\": 1.5, \"filter\": 1.5, \"than\": 1, \"not equal\": 2, \"whose\": 1\n",
    "\t\t\t},\n",
    "\t\t\t\n",
    "\t\t\t\"grouping\": {\n",
    "\t\t\t\t\"group by\": 3, \"grouped by\": 3, \"for each\": 2, \"per\": 1.5, \"group\": 2,\n",
    "\t\t\t\t\"average of\": 2, \"sum of\": 2, \"count of\": 2, \"grouped\": 2, \n",
    "\t\t\t\t\"categories\": 1, \"summarize\": 1.5, \"aggregate\": 2, \"having\": 2,\n",
    "\t\t\t\t\"average\": 2, \"sum\": 2, \"count\": 2, \"total\": 1\n",
    "\t\t\t},\n",
    "\t\t\t\n",
    "\t\t\t\"ordering\": {\n",
    "\t\t\t\t\"order by\": 3, \"sort by\": 3, \"arrange by\": 3, \"rank\": 2, \"top\": 2, \n",
    "\t\t\t\t\"ascending\": 2, \"descending\": 2, \"highest to lowest\": 2.5, \n",
    "\t\t\t\t\"lowest to highest\": 2.5, \"ordered\": 2, \"sorted\": 2, \"order\": 1.5, \n",
    "\t\t\t\t\"sort\": 1.5, \"arrange\": 1.5, \"limit\": 2, \"first\": 1.5\n",
    "\t\t\t},\n",
    "\t\t\t\n",
    "\t\t\t\"multi_table\": {\n",
    "\t\t\t\t\"join\": 3, \"both tables\": 3, \"across tables\": 3, \"multiple tables\": 3,\n",
    "\t\t\t\t\"related to\": 2, \"connection between\": 2, \"linking\": 2, \"relationship\": 2,\n",
    "\t\t\t\t\"from both\": 2, \"inner join\": 3, \"outer join\": 3, \"left join\": 3, \n",
    "\t\t\t\t\"tables\": 1.5, \"foreign key\": 3, \"two tables\": 3\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t\t\n",
    "\t\t# Calculate score for each category\n",
    "\t\tscores = {category: 0 for category in keywords.keys()}\n",
    "\t\t\n",
    "\t\t# Check for keyword matches and add corresponding weights\n",
    "\t\tfor category, kw_dict in keywords.items():\n",
    "\t\t\tfor kw, weight in kw_dict.items():\n",
    "\t\t\t\tif kw in question_lower:\n",
    "\t\t\t\t\tscores[category] += weight\n",
    "\t\t\n",
    "\t\t# Get the highest score\n",
    "\t\tmax_score = max(scores.values())\n",
    "\t\t\n",
    "\t\t# If no keywords match, default to comparison (typically most common)\n",
    "\t\tif max_score == 0:\n",
    "\t\t\treturn \"comparison\"\n",
    "\t\t\n",
    "\t\t# If there's a tie, implement a priority order\n",
    "\t\t# Prioritize more complex operations first\n",
    "\t\tif list(scores.values()).count(max_score) > 1:\n",
    "\t\t\tfor category in [\"multi_table\", \"grouping\", \"ordering\", \"comparison\"]:\n",
    "\t\t\t\tif scores[category] == max_score:\n",
    "\t\t\t\t\treturn category\n",
    "\t\t\n",
    "\t\t# Return the category with the highest score\n",
    "\t\treturn max(scores, key=scores.get)\n",
    "\n",
    "\tdef evaluate_accuracy(self, prediction_function_name):\n",
    "\t\t\"\"\"\n",
    "\t\tGives label wise accuracy of your model.\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tprediction_function_name: Callable\n",
    "\t\t\tThe function used for predicting labels.\n",
    "\t\t\t\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\taccs: dict\n",
    "\t\t\tThe accuracies of predicting each label.\n",
    "\t\tmain_acc: float\n",
    "\t\t\tThe overall average accuracy\n",
    "\t\t\"\"\"\n",
    "\t\tcorrect = Counter()\n",
    "\t\ttotal = Counter()\n",
    "\t\tmain_acc = 0\n",
    "\t\tmain_cnt = 0\n",
    "\t\tfor i in range(len(self.test_df)):\n",
    "\t\t\tq = self.test_df.loc[i][\"Question\"].split(\":\")[1].split(\"|\")[0].strip()\n",
    "\t\t\tgold_label = self.test_df.loc[i]['Label']\n",
    "\t\t\tif prediction_function_name(q) == gold_label:\n",
    "\t\t\t\tcorrect[gold_label] += 1\n",
    "\t\t\t\tmain_acc += 1\n",
    "\t\t\ttotal[gold_label] += 1\n",
    "\t\t\tmain_cnt += 1\n",
    "\t\taccs = {}\n",
    "\t\tfor label in self.ls_labels:\n",
    "\t\t\taccs[label] = (correct[label]/total[label])*100\n",
    "\t\treturn accs, 100*main_acc/main_cnt\n",
    "\n",
    "\tdef get_sentence_representation(self, sentence):\n",
    "\t\t\"\"\"\n",
    "\t\tGives the average word2vec representation of a sentence.\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tsentence: str\n",
    "\t\t\tThe sentence whose representation is to be returned.\n",
    "\t\t\t\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tsentence_vector: np.ndarray\n",
    "\t\t\tThe representation of the sentence.\n",
    "\t\t\"\"\"\n",
    "\t\t# Fill in your code here\n",
    "\t\tsentence_vector = np.zeros(300)\n",
    "\n",
    "\t\treturn sentence_vector\n",
    "\t\n",
    "\tdef init_ml_classifier(self):\n",
    "\t\t\"\"\"\n",
    "\t\tInitializes the ML classifier.\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\t\t\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\t\"\"\"\n",
    "\t\t# Fill in your code here\n",
    "\t\tself.classifier = None\n",
    "\t\n",
    "\tdef train_label_ml_classifier(self):\n",
    "\t\t\"\"\"\n",
    "\t\tTrain the classifier.\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\t\t\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\t\"\"\"\n",
    "\t\t# Fill in your code here\n",
    "\t\tpass\n",
    "\t\n",
    "\tdef predict_label_using_ml_classifier(self, question):\n",
    "\t\t\"\"\"\n",
    "\t\tPredicts the label of the question using the classifier.\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tquestion: str\n",
    "\t\t\tThe question whose label is to be predicted.\n",
    "\t\t\t\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tpredicted_label: str\n",
    "\t\t\tThe predicted label.\n",
    "\t\t\"\"\"\n",
    "\t\t# Fill in your code here\n",
    "\t\tpredicted_label = \"\"\n",
    "\n",
    "\t\treturn predicted_label\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
