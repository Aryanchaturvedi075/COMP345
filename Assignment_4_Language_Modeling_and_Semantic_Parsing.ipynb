{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aryanchaturvedi075/COMP345/blob/main/Assignment_4_Language_Modeling_and_Semantic_Parsing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FuO82RTBftK"
      },
      "source": [
        "# 1. Language Modeling\n",
        "\n",
        "In this part, let's generate text using a trigram language model.\n",
        "\n",
        "Go to https://drive.google.com/drive/folders/1zJqVF9yZiQT2iLeJjnc6BXUllr5km4Ul?usp=sharing and add this data to your google drive.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtZEcHthBeXz"
      },
      "source": [
        "Run the below code snippet. It will generate a URL which generates an authorization code.* Enter it below to give Colab access to your Google drive.\n",
        "\n",
        "*Copy function may not work. If so, manually copy the authorization code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW-dce7oJlyr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "74ba823e-ea83-4ee5-f626-f04890607fa7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-46b63aa8e6cf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni2pYuuQKaHY"
      },
      "source": [
        "When you run the `ls` command below, you should see these folders.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYENtyc7SOxA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d41cc04-3c3d-4b8e-ac83-14d17be33aae"
      },
      "source": [
        "!ls \"/content/drive/My Drive/a4_data\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "semantic-parser  tweets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.data import find\n",
        "import gensim\n",
        "import sklearn\n",
        "from sympy.parsing.sympy_parser import parse_expr\n",
        "\n",
        "np.random.seed(0)\n",
        "nltk.download('word2vec_sample')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hc3Sl1ZoO8b",
        "outputId": "08acb733-16d4-4914-c672-012058eee57a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package word2vec_sample to /root/nltk_data...\n",
            "[nltk_data]   Package word2vec_sample is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2Y7I_9lPoZS"
      },
      "source": [
        "Let us define a class for the language model and fill up the member functions according to the documentation.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZMOmElPSPHk"
      },
      "source": [
        "class NgramLM:\n",
        "\tdef __init__(self):\n",
        "\t\t\"\"\"\n",
        "\t\tN-gram Language Model\n",
        "\t\t\"\"\"\n",
        "\t\t# Dictionary to store next-word possibilities for bigrams. Maintains a list for each bigram.\n",
        "\t\tself.bigram_prefix_to_trigram = {}\n",
        "\n",
        "\t\t# Dictionary to store counts of corresponding next-word possibilities for bigrams. Maintains a list for each bigram.\n",
        "\t\tself.bigram_prefix_to_trigram_weights = {}\n",
        "\n",
        "\tdef load_trigrams(self):\n",
        "\t\t\"\"\"\n",
        "\t\tLoads the trigrams from the data file and fills the dictionaries defined above.\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\t\"\"\"\n",
        "\t\twith open(\"/content/drive/My Drive/a4_data/tweets/covid-tweets-2020-08-10-2020-08-21.trigrams.txt\") as f:\n",
        "\t\t\tlines = f.readlines()\n",
        "\t\t\tfor line in lines:\n",
        "\t\t\t\tword1, word2, word3, count = line.strip().split()\n",
        "\t\t\t\tif (word1, word2) not in self.bigram_prefix_to_trigram:\n",
        "\t\t\t\t\tself.bigram_prefix_to_trigram[(word1, word2)] = []\n",
        "\t\t\t\t\tself.bigram_prefix_to_trigram_weights[(word1, word2)] = []\n",
        "\t\t\t\tself.bigram_prefix_to_trigram[(word1, word2)].append(word3)\n",
        "\t\t\t\tself.bigram_prefix_to_trigram_weights[(word1, word2)].append(int(count))\n",
        "\n",
        "\tdef top_next_word(self, word1, word2, n=10):\n",
        "\t\t\"\"\"\n",
        "\t\tRetrieve top n next words and their probabilities given a bigram prefix.\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\t\tword1: str\n",
        "\t\t\tThe first word in the bigram.\n",
        "\t\tword2: str\n",
        "\t\t\tThe second word in the bigram.\n",
        "\t\tn: int\n",
        "\t\t\tNumber of words to return.\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\tnext_words: list\n",
        "\t\t\tThe retrieved top n next words.\n",
        "\t\tprobs: list\n",
        "\t\t\tThe probabilities corresponding to the retrieved words.\n",
        "\t\t\"\"\"\n",
        "\t\tnext_words = []\n",
        "\t\tprobs = []\n",
        "\n",
        "\t\t# write your code here\n",
        "\t\tpass\n",
        "\n",
        "\t\treturn next_words, probs\n",
        "\n",
        "\tdef sample_next_word(self, word1, word2, n=10):\n",
        "\t\t\"\"\"\n",
        "\t\tSample n next words and their probabilities given a bigram prefix using the probability distribution defined by frequency counts.\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\t\tword1: str\n",
        "\t\t\tThe first word in the bigram.\n",
        "\t\tword2: str\n",
        "\t\t\tThe second word in the bigram.\n",
        "\t\tn: int\n",
        "\t\t\tNumber of words to return.\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\tnext_words: list\n",
        "\t\t\tThe sampled n next words.\n",
        "\t\tprobs: list\n",
        "\t\t\tThe probabilities corresponding to the retrieved words.\n",
        "\t\t\"\"\"\n",
        "\t\tnext_words = []\n",
        "\t\tprobs = []\n",
        "\n",
        "\t\t# write your code here\n",
        "\t\tpass\n",
        "\n",
        "\t\treturn next_words, probs\n",
        "\n",
        "\tdef generate_sentences(self, prefix, beam=10, sampler=top_next_word, max_len=20):\n",
        "\t\t\"\"\"\n",
        "\t\tGenerate sentences using beam search.\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\t\tprefix: str\n",
        "\t\t\tString containing two (or more) words separated by spaces.\n",
        "\t\tbeam: int\n",
        "\t\t\tThe beam size.\n",
        "\t\tsampler: Callable\n",
        "\t\t\tThe function used to sample next word.\n",
        "\t\tmax_len: int\n",
        "\t\t\tMaximum length of sentence (as measure by number of words) to generate (excluding \"<EOS>\").\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\tsentences: list\n",
        "\t\t\tThe top generated sentences\n",
        "\t\tprobs: list\n",
        "\t\t\tThe probabilities corresponding to the generated sentences\n",
        "\t\t\"\"\"\n",
        "\t\tsentences = []\n",
        "\t\tprobs = []\n",
        "\n",
        "\t\t# write your code here\n",
        "\t\tpass\n",
        "\n",
        "\t\treturn sentences, probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let us evaluate the code."
      ],
      "metadata": {
        "id": "rSjinfI3pk4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your language model object\n",
        "language_model = NgramLM()\n",
        "# Load trigram data\n",
        "language_model.load_trigrams()"
      ],
      "metadata": {
        "id": "Z5c67e0Zok-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluating top next word prediction**"
      ],
      "metadata": {
        "id": "6RHinX6DppfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "next_words, probs = language_model.top_next_word(\"middle\", \"of\", 10)\n",
        "for word, prob in zip(next_words, probs):\n",
        "\tprint(word, prob)\n",
        "# Your first 5 lines of output should be exactly:\n",
        "# a 0.807981220657277\n",
        "# the 0.06948356807511737\n",
        "# pandemic 0.023943661971830985\n",
        "# this 0.016901408450704224\n",
        "# an 0.0107981220657277"
      ],
      "metadata": {
        "id": "bKRqRmIFovBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluating sample next word prediction**"
      ],
      "metadata": {
        "id": "vjsz__eEp4Y1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "next_words, probs = language_model.sample_next_word(\"middle\", \"of\", 10)\n",
        "for word, prob in zip(next_words, probs):\n",
        "\tprint(word, prob)\n",
        "# My first 5 lines of output look like this: (YOUR OUTPUT CAN BE DIFFERENT!)\n",
        "# a 0.807981220657277\n",
        "# pandemic 0.023943661971830985\n",
        "# august 0.0018779342723004694\n",
        "# stage 0.0018779342723004694\n",
        "# an 0.0107981220657277"
      ],
      "metadata": {
        "id": "OYfbYu3bo5LC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluating beam search**"
      ],
      "metadata": {
        "id": "A2QKVodfp_Qk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences, probs = language_model.generate_sentences(prefix=\"<BOS1> <BOS2> trump\", beam=10, sampler=language_model.top_next_word)\n",
        "for sent, prob in zip(sentences, probs):\n",
        "\tprint(sent, prob)\n",
        "print(\"#########################\\n\")\n",
        "# Your first 3 lines of output should be exactly:\n",
        "# <BOS1> <BOS2> trump eyes new unproven coronavirus treatment URL <EOS> 0.00021893147502903603\n",
        "# <BOS1> <BOS2> trump eyes new unproven coronavirus cure URL <EOS> 0.0001719607222046247\n",
        "# <BOS1> <BOS2> trump eyes new unproven virus cure promoted by mypillow ceo over unproven therapeutic URL <EOS> 9.773272077557522e-05\n",
        "\n",
        "sentences, probs = language_model.generate_sentences(prefix=\"<BOS1> <BOS2> biden\", beam=10, sampler=language_model.top_next_word)\n",
        "for sent, prob in zip(sentences, probs):\n",
        "\tprint(sent, prob)\n",
        "print(\"#########################\\n\")\n",
        "# Your first 3 lines of output should be exactly:\n",
        "# <BOS1> <BOS2> biden calls for a 30 bonus URL #cashgem #cashappfriday #stayathome <EOS> 0.0002495268686322749\n",
        "# <BOS1> <BOS2> biden says all u.s. governors should mandate masks <EOS> 1.6894510541025754e-05\n",
        "# <BOS1> <BOS2> biden says all u.s. governors question cost of a pandemic <EOS> 8.777606198953028e-07\n",
        "\n",
        "sentences, probs = language_model.generate_sentences(prefix=\"<BOS1> <BOS2> trump\", beam=10, sampler=language_model.sample_next_word)\n",
        "for sent, prob in zip(sentences, probs):\n",
        "\tprint(sent, prob)\n",
        "print(\"#########################\\n\")\n",
        "# My first 3 lines of output look like this: (YOUR OUTPUT CAN BE DIFFERENT!)\n",
        "# <BOS1> <BOS2> trump eyes new unproven coronavirus treatment URL <EOS> 0.00021893147502903603\n",
        "# <BOS1> <BOS2> trump eyes new unproven coronavirus cure URL <EOS> 0.0001719607222046247\n",
        "# <BOS1> <BOS2> trump eyes new unproven virus cure promoted by mypillow ceo over unproven therapeutic URL <EOS> 9.773272077557522e-05\n",
        "\n",
        "sentences, probs = language_model.generate_sentences(prefix=\"<BOS1> <BOS2> biden\", beam=10, sampler=language_model.sample_next_word)\n",
        "for sent, prob in zip(sentences, probs):\n",
        "\tprint(sent, prob)\n",
        "# My first 3 lines of output look like this: (YOUR OUTPUT CAN BE DIFFERENT!)\n",
        "# <BOS1> <BOS2> biden is elected <EOS> 0.001236227651321991\n",
        "# <BOS1> <BOS2> biden dropping ten points given trump a confidence trickster URL <EOS> 5.1049579351466146e-05\n",
        "# <BOS1> <BOS2> biden dropping ten points given trump four years <EOS> 4.367575122292103e-05"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XqBDhFAoa5D",
        "outputId": "ac621bc3-1600-4d66-8f2c-b671a0397de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#########################\n",
            "\n",
            "#########################\n",
            "\n",
            "#########################\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UShw7ULDcOwU"
      },
      "source": [
        "# 2. Semantic Parsing\n",
        "\n",
        "In this part, you are going to build semantic parsers!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj2nWqZ9dZUs",
        "outputId": "ddf87040-19cc-4036-c7ff-1df0654b5e48"
      },
      "source": [
        "!ls \"/content/drive/My Drive/a4_data/semantic-parser\"\n",
        "parser_files = \"/content/drive/My Drive/a4_data/semantic-parser\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "math_train.tsv\tmusic_asst_train.txt\tmusic_asst_val_ques.txt  sql_val.tsv\n",
            "math_val.tsv\tmusic_asst_val_ans.txt\tsql_train.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Classifier for Text2SQL Parsing"
      ],
      "metadata": {
        "id": "qXMnLopxufMw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get an idea of what the data looks like:"
      ],
      "metadata": {
        "id": "Avtk9AUdutX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(f'{parser_files}/sql_train.tsv', sep='\\t')\n",
        "\n",
        "for i in range(10):\n",
        "    ques = train_df.loc[i][\"Question\"]\n",
        "    parse = train_df.loc[i][\"Parse\"]\n",
        "    label = train_df.loc[i][\"Label\"]\n",
        "    print(\"Question: \", ques)\n",
        "    print(\"Parse: \", parse)\n",
        "    print(\"Label: \", label)\n",
        "    print(\"-\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oU5XZEfEun_N",
        "outputId": "838bfc0f-6889-4c5e-9c2f-de77c62a8a10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question:  tracking_orders: which order's shipment tracking number is \"3452\"? give me the id of the order. | customers : customer_id , customer_name , customer_details | invoices : invoice_number , invoice_date , invoice_details | orders : order_id , customer_id , order_status , date_order_placed , order_details | products : product_id , product_name , product_details | order_items : order_item_id , product_id , order_id , order_item_status , order_item_details | shipments : shipment_id , order_id , invoice_number , shipment_tracking_number , shipment_date , other_shipment_details | shipment_items : shipment_id , order_item_id\n",
            "Parse:  select order_id from shipments where shipment_tracking_number = \"3452\"\n",
            "Label:  comparison\n",
            "--------------------------------------------------------------------------------\n",
            "Question:  student_assessment: what are the id of students who registered course 301? | addresses : address_id , line_1 , line_2 , city , zip_postcode , state_province_county , country | people : person_id , first_name , middle_name , last_name , cell_mobile_number , email_address , login_name , password | students : student_id , student_details | courses : course_id , course_name , course_description , other_details | people_addresses : person_address_id , person_id , address_id , date_from , date_to | student_course_registrations : student_id , course_id , registration_date | student_course_attendance : student_id , course_id , date_of_attendance | candidates : candidate_id , candidate_details | candidate_assessments : candidate_id , qualification , assessment_date , asessment_outcome_code\n",
            "Parse:  select student_id from student_course_attendance where course_id = 301\n",
            "Label:  comparison\n",
            "--------------------------------------------------------------------------------\n",
            "Question:  store_1: what is the title, phone and hire date of nancy edwards? | artists : id , name | sqlite_sequence : name , seq | albums : id , title , artist_id | employees : id , last_name , first_name , title , reports_to , birth_date , hire_date , address , city , state , country , postal_code , phone , fax , email | customers : id , first_name , last_name , company , address , city , state , country , postal_code , phone , fax , email , support_rep_id | genres : id , name | invoices : id , customer_id , invoice_date , billing_address , billing_city , billing_state , billing_country , billing_postal_code , total | media_types : id , name | tracks : id , name , album_id , media_type_id , genre_id , composer , milliseconds , bytes , unit_price | invoice_lines : id , invoice_id , track_id , unit_price , quantity | playlists : id , name | playlist_tracks : playlist_id , track_id\n",
            "Parse:  select title , phone , hire_date from employees where first_name = \"nancy\" and last_name = \"edwards\";\n",
            "Label:  comparison\n",
            "--------------------------------------------------------------------------------\n",
            "Question:  match_season: what are the names of all colleges that have two or more players? | country : country_id , country_name , capital , official_native_language | team : team_id , name | match_season : season , player , position , country , team , draft_pick_number , draft_class , college | player : player_id , player , years_played , total_wl , singles_wl , doubles_wl , team\n",
            "Parse:  select college from match_season group by college having count(*) >= 2\n",
            "Label:  grouping\n",
            "--------------------------------------------------------------------------------\n",
            "Question:  apartment_rentals: show the guest first names, start dates, and end dates of all the apartment bookings. | apartment_buildings : building_id , building_short_name , building_full_name , building_description , building_address , building_manager , building_phone | apartments : apt_id , building_id , apt_type_code , apt_number , bathroom_count , bedroom_count , room_count | apartment_facilities : apt_id , facility_code | guests : guest_id , gender_code , guest_first_name , guest_last_name , date_of_birth | apartment_bookings : apt_booking_id , apt_id , guest_id , booking_status_code , booking_start_date , booking_end_date | view_unit_status : apt_id , apt_booking_id , status_date , available_yn\n",
            "Parse:  select t2.guest_first_name , t1.booking_start_date , t1.booking_start_date from apartment_bookings as t1 join guests as t2 on t1.guest_id = t2.guest_id\n",
            "Label:  multi_table\n",
            "--------------------------------------------------------------------------------\n",
            "Question:  game_1: show all student ids with the number of sports and total number of games played | student : stuid , lname , fname , age , sex , major , advisor , city_code | video_games : gameid , gname , gtype | plays_games : stuid , gameid , hours_played | sportsinfo : stuid , sportname , hoursperweek , gamesplayed , onscholarship\n",
            "Parse:  select stuid , count(*) , sum(gamesplayed) from sportsinfo group by stuid\n",
            "Label:  grouping\n",
            "--------------------------------------------------------------------------------\n",
            "Question:  icfp_1: give me a list of all the last names of authors sorted in alphabetical order | inst : instid , name , country | authors : authid , lname , fname | papers : paperid , title | authorship : authid , instid , paperid , authorder\n",
            "Parse:  select lname from authors order by lname\n",
            "Label:  ordering\n",
            "--------------------------------------------------------------------------------\n",
            "Question:  cre_doc_tracking_db: list the names of the employees who authorized the destruction of documents and the employees who destroyed the corresponding documents. | ref_document_types : document_type_code , document_type_name , document_type_description | ref_calendar : calendar_date , day_number | ref_locations : location_code , location_name , location_description | roles : role_code , role_name , role_description | all_documents : document_id , date_stored , document_type_code , document_name , document_description , other_details | employees : employee_id , role_code , employee_name , gender_mfu , date_of_birth , other_details | document_locations : document_id , location_code , date_in_location_from , date_in_locaton_to | documents_to_be_destroyed : document_id , destruction_authorised_by_employee_id , destroyed_by_employee_id , planned_destruction_date , actual_destruction_date , other_details\n",
            "Parse:  select t2.employee_name , t3.employee_name from documents_to_be_destroyed as t1 join employees as t2 on t1.destruction_authorised_by_employee_id = t2.employee_id join employees as t3 on t1.destroyed_by_employee_id = t3.employee_id;\n",
            "Label:  multi_table\n",
            "--------------------------------------------------------------------------------\n",
            "Question:  student_assessment: list the names of courses in alphabetical order? | addresses : address_id , line_1 , line_2 , city , zip_postcode , state_province_county , country | people : person_id , first_name , middle_name , last_name , cell_mobile_number , email_address , login_name , password | students : student_id , student_details | courses : course_id , course_name , course_description , other_details | people_addresses : person_address_id , person_id , address_id , date_from , date_to | student_course_registrations : student_id , course_id , registration_date | student_course_attendance : student_id , course_id , date_of_attendance | candidates : candidate_id , candidate_details | candidate_assessments : candidate_id , qualification , assessment_date , asessment_outcome_code\n",
            "Parse:  select course_name from courses order by course_name\n",
            "Label:  ordering\n",
            "--------------------------------------------------------------------------------\n",
            "Question:  soccer_2: list all information about college sorted by enrollment number in the ascending order. | college : cname , state , enr | player : pid , pname , ycard , hs | tryout : pid , cname , ppos , decision\n",
            "Parse:  select * from college order by enr\n",
            "Label:  ordering\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us define a class for the slot predictor and fill up the member functions according to the documentation.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "wHWkViC8wwmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Text2SQLParser:\n",
        "\tdef __init__(self):\n",
        "\t\t\"\"\"\n",
        "\t\tBasic Text2SQL Parser. This module just attempts to classify the user queries into different \"categories\" of SQL queries.\n",
        "\t\t\"\"\"\n",
        "\t\tself.parser_files = parser_files\n",
        "\t\tself.word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
        "\t\tself.word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(self.word2vec_sample, binary=False)\n",
        "\n",
        "\t\tself.train_file = \"sql_train.tsv\"\n",
        "\t\tself.test_file = \"sql_val.tsv\"\n",
        "\n",
        "\tdef load_data(self):\n",
        "\t\t\"\"\"\n",
        "\t\tLoad the data from file.\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\t\"\"\"\n",
        "\t\tself.train_df = pd.read_csv(self.parser_files + \"/\" + self.train_file, sep=\"\\t\")\n",
        "\t\tself.test_df = pd.read_csv(self.parser_files + \"/\" + self.test_file, sep=\"\\t\")\n",
        "\n",
        "\t\tself.ls_labels = list(self.train_df[\"Label\"].unique())\n",
        "\n",
        "\tdef predict_label_using_keywords(self, question):\n",
        "\t\t\"\"\"\n",
        "\t\tPredicts the label for the question using custom-defined keywords.\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\t\tquestion: str\n",
        "\t\t\tThe question whose label is to be predicted.\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\tlabel: str\n",
        "\t\t\tThe predicted label.\n",
        "\t\t\"\"\"\n",
        "\t\t# Fill in your code here.\n",
        "\t\tlabel = \"\"\n",
        "\n",
        "\t\treturn label\n",
        "\n",
        "\tdef evaluate_accuracy(self, prediction_function_name):\n",
        "\t\t\"\"\"\n",
        "\t\tGives label wise accuracy of your model.\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\t\tprediction_function_name: Callable\n",
        "\t\t\tThe function used for predicting labels.\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\taccs: dict\n",
        "\t\t\tThe accuracies of predicting each label.\n",
        "\t\tmain_acc: float\n",
        "\t\t\tThe overall average accuracy\n",
        "\t\t\"\"\"\n",
        "\t\tcorrect = Counter()\n",
        "\t\ttotal = Counter()\n",
        "\t\tmain_acc = 0\n",
        "\t\tmain_cnt = 0\n",
        "\t\tfor i in range(len(self.test_df)):\n",
        "\t\t\tq = self.test_df.loc[i][\"Question\"].split(\":\")[1].split(\"|\")[0].strip()\n",
        "\t\t\tgold_label = self.test_df.loc[i]['Label']\n",
        "\t\t\tif prediction_function_name(q) == gold_label:\n",
        "\t\t\t\tcorrect[gold_label] += 1\n",
        "\t\t\t\tmain_acc += 1\n",
        "\t\t\ttotal[gold_label] += 1\n",
        "\t\t\tmain_cnt += 1\n",
        "\t\taccs = {}\n",
        "\t\tfor label in self.ls_labels:\n",
        "\t\t\taccs[label] = (correct[label]/total[label])*100\n",
        "\t\treturn accs, 100*main_acc/main_cnt\n",
        "\n",
        "\tdef get_sentence_representation(self, sentence):\n",
        "\t\t\"\"\"\n",
        "\t\tGives the average word2vec representation of a sentence.\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\t\tsentence: str\n",
        "\t\t\tThe sentence whose representation is to be returned.\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\tsentence_vector: np.ndarray\n",
        "\t\t\tThe representation of the sentence.\n",
        "\t\t\"\"\"\n",
        "\t\t# Fill in your code here\n",
        "\t\tsentence_vector = np.zeros(300)\n",
        "\n",
        "\t\treturn sentence_vector\n",
        "\n",
        "\tdef init_ml_classifier(self):\n",
        "\t\t\"\"\"\n",
        "\t\tInitializes the ML classifier.\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\t\"\"\"\n",
        "\t\t# Fill in your code here\n",
        "\t\tself.classifier = None\n",
        "\n",
        "\tdef train_label_ml_classifier(self):\n",
        "\t\t\"\"\"\n",
        "\t\tTrain the classifier.\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\t\"\"\"\n",
        "\t\t# Fill in your code here\n",
        "\t\tpass\n",
        "\n",
        "\tdef predict_label_using_ml_classifier(self, question):\n",
        "\t\t\"\"\"\n",
        "\t\tPredicts the label of the question using the classifier.\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\t\tquestion: str\n",
        "\t\t\tThe question whose label is to be predicted.\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\tpredicted_label: str\n",
        "\t\t\tThe predicted label.\n",
        "\t\t\"\"\"\n",
        "\t\t# Fill in your code here\n",
        "\t\tpredicted_label = \"\"\n",
        "\n",
        "\t\treturn predicted_label"
      ],
      "metadata": {
        "id": "ohN8q_kRwuAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let us evaluate the code:"
      ],
      "metadata": {
        "id": "W1VPohD1xPDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your text2sql parser object\n",
        "sql_parser = Text2SQLParser()\n",
        "\n",
        "# Load the data files\n",
        "sql_parser.load_data()\n",
        "\n",
        "# Initialize the ML classifier\n",
        "sql_parser.init_ml_classifier()\n",
        "\n",
        "# Train the classifier\n",
        "sql_parser.train_label_ml_classifier()"
      ],
      "metadata": {
        "id": "4M0n5v1qxPDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluating the keyword-based label classifier**"
      ],
      "metadata": {
        "id": "omFt9bujxPDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"------------- Evaluating keyword-based label classifier -------------\")\n",
        "accs, _ = sql_parser.evaluate_accuracy(sql_parser.predict_label_using_keywords)\n",
        "for label in accs:\n",
        "\tprint(label + \": \" + str(accs[label]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6d2d4cc-bb4a-402b-b521-01689cdb0441",
        "id": "p35SjztuxPDV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------- Evaluating keyword-based label classifier -------------\n",
            "comparison: 0.0\n",
            "grouping: 0.0\n",
            "multi_table: 0.0\n",
            "ordering: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluating the Evaluate ML classifier**"
      ],
      "metadata": {
        "id": "56lCb-qIxjue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"------------- Evaluating ML classifier -------------\")\n",
        "sql_parser.train_label_ml_classifier()\n",
        "_, overall_acc = sql_parser.evaluate_accuracy(sql_parser.predict_label_using_ml_classifier)\n",
        "print(\"Overall accuracy: \", str(overall_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wWeLxNMxJMM",
        "outputId": "aa95dc3f-2d9d-4c14-a235-0e5235f9359b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------- Evaluating ML classifier -------------\n",
            "Overall accuracy:  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Slot Predictor for Music Assistant"
      ],
      "metadata": {
        "id": "XF8hlL3OszFA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get an idea of what the data looks like:"
      ],
      "metadata": {
        "id": "iYTnuSCkqii7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbtOC6eecMNp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e879384-4bbf-4c9c-eed6-a9e3ea033105"
      },
      "source": [
        "train_data = []\n",
        "for line in open(f'{parser_files}/music_asst_train.txt'):\n",
        "    train_data.append(json.loads(line))\n",
        "\n",
        "# print a few examples\n",
        "for i in range(5):\n",
        "    print(train_data[i])\n",
        "    print(\"-\"*80)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'question': 'Add an album to my Sylvia Plath playlist.', 'slots': {'music_item': 'album', 'playlist_owner': 'my', 'playlist': 'Sylvia Plath'}}\n",
            "--------------------------------------------------------------------------------\n",
            "{'question': 'add Diarios de Bicicleta to my la la playlist', 'slots': {'playlist': 'Diarios de Bicicleta', 'playlist_owner': 'my', 'entity_name': 'la la'}}\n",
            "--------------------------------------------------------------------------------\n",
            "{'question': 'add iemand als jij to my playlist named In The Name Of Blues', 'slots': {'entity_name': 'iemand als jij', 'playlist_owner': 'my', 'playlist': 'In The Name Of Blues'}}\n",
            "--------------------------------------------------------------------------------\n",
            "{'question': 'Put dschiwan gasparjan into the Cool Down playlist. ', 'slots': {'artist': 'dschiwan gasparjan', 'playlist': 'Cool Down'}}\n",
            "--------------------------------------------------------------------------------\n",
            "{'question': 'add the album to my Top 100 Indie Tracks on Spotify playlist', 'slots': {'music_item': 'album', 'playlist_owner': 'my', 'playlist': 'Top 100 Indie Tracks on Spotify'}}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMV-NkkAb6X3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afd8a555-79af-4238-9afe-0a89e31413ff"
      },
      "source": [
        "test_questions = []\n",
        "for line in open(f'{parser_files}/music_asst_val_ques.txt'):\n",
        "    test_questions.append(json.loads(line))\n",
        "\n",
        "test_answers = []\n",
        "for line in open(f'{parser_files}/music_asst_val_ans.txt'):\n",
        "    test_answers.append(json.loads(line))\n",
        "\n",
        "# print a few examples\n",
        "for i in range(5):\n",
        "    print(test_questions[i])\n",
        "    print(test_answers[i])\n",
        "    print(\"-\"*80)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Add an artist to Jukebox Boogie Rhythm & Blues\n",
            "{'slots': {'music_item': 'artist', 'playlist': 'Jukebox Boogie Rhythm & Blues'}}\n",
            "--------------------------------------------------------------------------------\n",
            "add nuba to my Metal Party playlist\n",
            "{'slots': {'entity_name': 'nuba', 'playlist_owner': 'my', 'playlist': 'Metal Party'}}\n",
            "--------------------------------------------------------------------------------\n",
            "Add the album to the The Sweet Suite playlist.\n",
            "{'slots': {'music_item': 'album', 'playlist': 'The Sweet Suite'}}\n",
            "--------------------------------------------------------------------------------\n",
            "Add a song to my playlist madden nfl 16\n",
            "{'slots': {'music_item': 'song', 'playlist_owner': 'my', 'playlist': 'madden nfl 16'}}\n",
            "--------------------------------------------------------------------------------\n",
            "Can you put this song from Yutaka Ozaki onto my this is miles davis playlist?\n",
            "{'slots': {'music_item': 'song', 'artist': 'Yutaka Ozaki', 'playlist_owner': 'my', 'playlist': 'this is miles davis'}}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us define a class for the slot predictor and fill up the member functions according to the documentation.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "O04fqA1Xq5nL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJHTfEMqb6X8"
      },
      "source": [
        "class MusicAsstSlotPredictor:\n",
        "\tdef __init__(self):\n",
        "\t\t\"\"\"\n",
        "\t\tSlot Predictor for the Music Assistant.\n",
        "\t\t\"\"\"\n",
        "\t\tself.parser_files = parser_files\n",
        "\t\tself.train_data = []\n",
        "\t\tself.test_questions = []\n",
        "\t\tself.test_answers = []\n",
        "\n",
        "\t\tself.slot_names = set()\n",
        "\n",
        "\tdef load_data(self):\n",
        "\t\t\"\"\"\n",
        "\t\tLoad the data from file.\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\t\"\"\"\n",
        "\t\twith open(f'{self.parser_files}/music_asst_train.txt') as f:\n",
        "\t\t\tlines = f.readlines()\n",
        "\t\t\tfor line in lines:\n",
        "\t\t\t\tself.train_data.append(json.loads(line))\n",
        "\n",
        "\t\twith open(f'{self.parser_files}/music_asst_val_ques.txt') as f:\n",
        "\t\t\tlines = f.readlines()\n",
        "\t\t\tfor line in lines:\n",
        "\t\t\t\tself.test_questions.append(json.loads(line))\n",
        "\n",
        "\t\twith open(f'{self.parser_files}/music_asst_val_ans.txt') as f:\n",
        "\t\t\tlines = f.readlines()\n",
        "\t\t\tfor line in lines:\n",
        "\t\t\t\tself.test_answers.append(json.loads(line))\n",
        "\n",
        "\tdef get_slots(self):\n",
        "\t\t\"\"\"\n",
        "\t\tGet all the unique slots.\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\t\"\"\"\n",
        "\t\tfor sample in self.train_data:\n",
        "\t\t\tfor slot_name in sample['slots']:\n",
        "\t\t\t\tself.slot_names.add(slot_name)\n",
        "\n",
        "\tdef predict_slot_values(self, question):\n",
        "\t\t\"\"\"\n",
        "\t\tPredicts the values for the slots.\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\t\tquestion: str\n",
        "\t\t\tThe question for which the slots are to be predicted.\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\tslots: dict\n",
        "\t\t\tThe predicted slots.\n",
        "\t\t\"\"\"\n",
        "\t\twords = question.split()\n",
        "\t\tslots = {}\n",
        "\t\tfor slot_name in self.slot_names:\n",
        "\t\t\tslots[slot_name] = None\n",
        "\t\tfor slot_name in self.slot_names:\n",
        "\t\t\t# Fill in your code to idenfity the slot value. By default, they are initialized to None.\n",
        "\t\t\tpass\n",
        "\t\treturn slots\n",
        "\n",
        "\tdef get_confusion_matrix(self, slot_prediction_function, questions, answers):\n",
        "\t\t\"\"\"\n",
        "\t\tFind the true positive, true negative, false positive, and false negative examples with respect to the prediction of a slot being active or not (irrespective of value assigned).\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\t\tslot_prediction_function: Callable\n",
        "\t\t\tThe function used for predicting slot values.\n",
        "\t\tquestions: list\n",
        "\t\t\tThe test questions\n",
        "\t\tanswers: list\n",
        "\t\t\tThe ground-truth test answers\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\ttp: dict\n",
        "\t\t\tThe indices of true positive examples are listed for each slot\n",
        "\t\tfp: dict\n",
        "\t\t\tThe indices of false positive examples are listed for each slot\n",
        "\t\ttn: dict\n",
        "\t\t\tThe indices of true negative examples are listed for each slot\n",
        "\t\tfn: dict\n",
        "\t\t\tThe indices of false negative examples are listed for each slot\n",
        "\t\t\"\"\"\n",
        "\t\ttp = {}\n",
        "\t\tfp = {}\n",
        "\t\ttn = {}\n",
        "\t\tfn = {}\n",
        "\t\tfor slot_name in self.slot_names:\n",
        "\t\t\ttp[slot_name] = []\n",
        "\t\tfor slot_name in self.slot_names:\n",
        "\t\t\tfp[slot_name] = []\n",
        "\t\tfor slot_name in self.slot_names:\n",
        "\t\t\ttn[slot_name] = []\n",
        "\t\tfor slot_name in self.slot_names:\n",
        "\t\t\tfn[slot_name] = []\n",
        "\t\tfor i, question in enumerate(questions):\n",
        "\t\t\t# Fill in your code here\n",
        "\t\t\tpass\n",
        "\t\treturn tp, fp, tn, fn\n",
        "\n",
        "\tdef evaluate_slot_prediction_recall(self, slot_prediction_function):\n",
        "\t\t\"\"\"\n",
        "\t\tEvaluates the recall for the slot predictor. Note: This also takes into account the exact value predicted for the slot\n",
        "\t\tand not just whether the slot is active like in the get_confusion_matrix() method\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\t\tslot_prediction_function: Callable\n",
        "\t\t\tThe function used for predicting slot values.\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\taccs: dict\n",
        "\t\t\tThe recall for predicting the value for each slot.\n",
        "\t\t\"\"\"\n",
        "\t\tcorrect = Counter()\n",
        "\t\ttotal = Counter()\n",
        "\t\t# predict slots for each question\n",
        "\t\tfor i, question in enumerate(self.test_questions):\n",
        "\t\t\ti = self.test_questions.index(question)\n",
        "\t\t\tgold_slots = self.test_answers[i]['slots']\n",
        "\t\t\tpredicted_slots = slot_prediction_function(question)\n",
        "\t\t\tfor name in self.slot_names:\n",
        "\t\t\t\tif name in gold_slots:\n",
        "\t\t\t\t\ttotal[name] += 1.0\n",
        "\t\t\t\t\tif predicted_slots.get(name, None) != None and predicted_slots.get(name).lower() == gold_slots.get(name).lower():\n",
        "\t\t\t\t\t\tcorrect[name] += 1.0\n",
        "\t\taccs = {}\n",
        "\t\tfor name in self.slot_names:\n",
        "\t\t\taccs[name] = (correct[name] / total[name]) * 100\n",
        "\t\treturn accs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let us evaluate the code:"
      ],
      "metadata": {
        "id": "TO35_iGAq_ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your semantic parser object\n",
        "semantic_parser = MusicAsstSlotPredictor()\n",
        "# Load semantic parser data\n",
        "semantic_parser.load_data()"
      ],
      "metadata": {
        "id": "3mO_XMP2tvKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluating the Slot Predictor**"
      ],
      "metadata": {
        "id": "fOC8VFKmr-Qw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at the slots\n",
        "print(\"------------- slots -------------\")\n",
        "semantic_parser.get_slots()\n",
        "print(semantic_parser.slot_names)\n",
        "\n",
        "# Evaluate slot predictor\n",
        "# Our reference implementation got these numbers on the validation set. You can ask others on Slack what they got.\n",
        "# playlist_owner: 100.0\n",
        "# music_item: 100.0\n",
        "# entity_name: 16.666666666666664\n",
        "# artist: 14.285714285714285\n",
        "# playlist: 52.94117647058824\n",
        "print(\"------------- Evaluating slot predictor -------------\")\n",
        "accs = semantic_parser.evaluate_slot_prediction_recall(semantic_parser.predict_slot_values)\n",
        "for slot in accs:\n",
        "\tprint(slot + \": \" + str(accs[slot]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wueXFUQyq-sm",
        "outputId": "f7d5edd5-243f-43b1-b2ba-81b7a543f8fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------- slots -------------\n",
            "{'playlist_owner', 'playlist', 'artist', 'music_item', 'entity_name'}\n",
            "------------- Evaluating slot predictor -------------\n",
            "playlist_owner: 0.0\n",
            "playlist: 0.0\n",
            "artist: 0.0\n",
            "music_item: 0.0\n",
            "entity_name: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluating the Confusion Matrix**"
      ],
      "metadata": {
        "id": "7dYacTp0sJD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Confusion matrix examples\n",
        "print(\"------------- Confusion matrix examples -------------\")\n",
        "tp, fp, tn, fn = semantic_parser.get_confusion_matrix(semantic_parser.predict_slot_values, semantic_parser.test_questions, semantic_parser.test_answers)\n",
        "print(tp)\n",
        "print(fp)\n",
        "print(tn)\n",
        "print(fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9u2FT1A4sF4Q",
        "outputId": "93935bc6-7873-4905-ab33-53a49cb26d26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------- Confusion matrix examples -------------\n",
            "{'playlist_owner': [], 'playlist': [], 'artist': [], 'music_item': [], 'entity_name': []}\n",
            "{'playlist_owner': [], 'playlist': [], 'artist': [], 'music_item': [], 'entity_name': []}\n",
            "{'playlist_owner': [], 'playlist': [], 'artist': [], 'music_item': [], 'entity_name': []}\n",
            "{'playlist_owner': [], 'playlist': [], 'artist': [], 'music_item': [], 'entity_name': []}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Math Word Problem Parsing"
      ],
      "metadata": {
        "id": "vmqzEih0yF-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get an idea of what the data looks like:"
      ],
      "metadata": {
        "id": "aqfFfjNvyF-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(f'{parser_files}/math_train.tsv', sep='\\t')\n",
        "\n",
        "for i in range(10):\n",
        "    ques = train_df.loc[i][\"Question\"]\n",
        "    eq = train_df.loc[i][\"Equation\"]\n",
        "    print(\"Question: \", ques)\n",
        "    print(\"Parse: \", eq)\n",
        "    print(\"-\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "acefdba3-dac8-4c1c-f42c-3c9abe3de6fa",
        "id": "TW5AwGN9yF-F"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question:  Julia played tag with 18 kids on monday. She played tag with 10 kids on tuesday. How many more kids did she play with on monday than on tuesday?\n",
            "Parse:  18.0 - 10.0\n",
            "--------------------------------------------------------------------------------\n",
            "Question:  5 red peaches and 11 green peaches are in the basket. How many more green peaches than red peaches are in the basket?\n",
            "Parse:  11.0 - 5.0\n",
            "--------------------------------------------------------------------------------\n",
            "Question:  Matthew gave 6 crackers to each his friends. If he had 36 crackers How many friends did he give crackers to?\n",
            "Parse:  36.0 / 6.0\n",
            "--------------------------------------------------------------------------------\n",
            "Question:  6 packs of dvds can be bought with 120 dollars. How much does each pack cost?\n",
            "Parse:  120.0 / 6.0\n",
            "--------------------------------------------------------------------------------\n",
            "Question:  Emily is making bead necklaces for her friends. She made 11 necklaces and each necklace takes 28 beads. How many beads did Emily have?\n",
            "Parse:  11.0 * 28.0\n",
            "--------------------------------------------------------------------------------\n",
            "Question:  The Razorback t-shirt shop makes $ 23 dollars off each t-shirt sold. During the Arkansas and Texas tech game they made $ 230 by selling t-shirts. How many t-shirts did they sell?\n",
            "Parse:  230.0 / 23.0\n",
            "--------------------------------------------------------------------------------\n",
            "Question:  He then went to see the oranges being harvested. He found out that they harvested 54 sacks of oranges. How many days did it take to harvest them if they harvested 18 sacks of oranges per day?\n",
            "Parse:  54.0 / 18.0\n",
            "--------------------------------------------------------------------------------\n",
            "Question:  Nell collects baseball cards. She gave 301 of her cards to Jeff and now has 154 cards left.. How many cards did Nell have initially?\n",
            "Parse:  154.0 + 301.0\n",
            "--------------------------------------------------------------------------------\n",
            "Question:  Emily is making bead necklaces for her friends. She was able to make 6 necklaces and she had 18 beads. How many beads did each necklace need?\n",
            "Parse:  18.0 / 6.0\n",
            "--------------------------------------------------------------------------------\n",
            "Question:  He then went to see the oranges being harvested. He found out that they harvest 8 sacks per day. How many days will it take to harvest 24 sacks of oranges?\n",
            "Parse:  24.0 / 8.0\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us define a class for the slot predictor and fill up the member functions according to the documentation.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "9Rx918HXyF-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MathParser:\n",
        "\tdef __init__(self):\n",
        "\t\t\"\"\"\n",
        "\t\tMath Word Problem Solver.\n",
        "\t\t\"\"\"\n",
        "\t\tself.parser_files = parser_files\n",
        "\t\tself.word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
        "\t\tself.word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(self.word2vec_sample, binary=False)\n",
        "\n",
        "\t\tself.train_file = \"math_train.tsv\"\n",
        "\t\tself.test_file = \"math_val.tsv\"\n",
        "\n",
        "\tdef load_data(self):\n",
        "\t\t\"\"\"\n",
        "\t\tLoad the data from file.\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\t\"\"\"\n",
        "\t\tself.train_df = pd.read_csv(self.parser_files + \"/\" + self.train_file, sep=\"\\t\")\n",
        "\t\tself.test_df = pd.read_csv(self.parser_files + \"/\" + self.test_file, sep=\"\\t\")\n",
        "\n",
        "\tdef init_model(self):\n",
        "\t\t\"\"\"\n",
        "\t\tInitializes the ML classifier.\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\t\"\"\"\n",
        "\t\t# Fill in your code here\n",
        "\t\tpass\n",
        "\n",
        "\tdef predict_equation_from_question(self, question):\n",
        "\t\t\"\"\"\n",
        "\t\tPredicts the equation for the question.\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\t\tquestion: str\n",
        "\t\t\tThe question whose equation is to be predicted.\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\tequation: str\n",
        "\t\t\tThe predicted equation.\n",
        "\t\t\"\"\"\n",
        "\t\t# Fill in your code here.\n",
        "\t\teq = \"\"\n",
        "\n",
        "\t\tpass\n",
        "\n",
        "\t\treturn eq\n",
        "\n",
        "\tdef ans_evaluator(self, equation):\n",
        "\t\t\"\"\"\n",
        "\t\tParses the equation to obtain the final answer.\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\t\tequation: str\n",
        "\t\t\tThe equation to be parsed.\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\tfinal_ans: float\n",
        "\t\t\tThe final answer.\n",
        "\t\t\"\"\"\n",
        "\t\ttry:\n",
        "\t\t\tfinal_ans = parse_expr(equation, evaluate = True)\n",
        "\t\texcept:\n",
        "\t\t\tfinal_ans = -1000.112\n",
        "\t\treturn final_ans\n",
        "\n",
        "\tdef evaluate_accuracy(self, prediction_function_name):\n",
        "\t\t\"\"\"\n",
        "\t\tGives accuracy of your model.\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\t\tprediction_function_name: Callable\n",
        "\t\t\tThe function used for predicting equations.\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\tmain_acc: float\n",
        "\t\t\tThe overall average accuracy\n",
        "\t\t\"\"\"\n",
        "\t\tacc = 0\n",
        "\t\ttot = 0\n",
        "\t\tfor i in range(len(self.test_df)):\n",
        "\t\t\tques = self.test_df.loc[i][\"Question\"]\n",
        "\t\t\tgold_ans = self.test_df.loc[i][\"Answer\"]\n",
        "\t\t\tpred_eq = prediction_function_name(ques)\n",
        "\t\t\tpred_ans = self.ans_evaluator(pred_eq)\n",
        "\n",
        "\t\t\tif abs(gold_ans - pred_ans) < 0.1:\n",
        "\t\t\t\tacc += 1\n",
        "\t\t\ttot += 1\n",
        "\t\treturn 100*acc/tot"
      ],
      "metadata": {
        "id": "uLZVW4_KyX26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let us evaluate the code:"
      ],
      "metadata": {
        "id": "IK76ky0IyhzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your math parser object\n",
        "math_parser = MathParser()\n",
        "\n",
        "# Load the data files\n",
        "math_parser.load_data()\n",
        "\n",
        "# Initialize and train the model\n",
        "math_parser.init_model()"
      ],
      "metadata": {
        "id": "4UkMNb8VyhzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Get Accuracy**"
      ],
      "metadata": {
        "id": "ybGR2gtuyhzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"------------- Accuracy of Equation Prediction -------------\")\n",
        "acc = math_parser.evaluate_accuracy(math_parser.predict_equation_from_question)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10eed3e2-233d-40e0-86e7-3836df6fbe02",
        "id": "vEbTgSIdyhzE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------- Accuracy of Equation Prediction -------------\n",
            "Accuracy:  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J5vt4Z70yqgr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}